{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "https://tsfresh.readthedocs.io/en/latest/api/tsfresh.feature_extraction.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.size'] = 14\n",
    "\n",
    "from tsfresh import extract_features\n",
    "from xgboost import XGBClassifier, plot_tree\n",
    "\n",
    "%run plot.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "DATA/x_ts_L60_Z12_A500_DX50_bias5_N10000.dat not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m fnamex\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDATA/x_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mstr0\n\u001b[1;32m      3\u001b[0m fnamey\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDATA/y_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mstr0\n\u001b[0;32m----> 5\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadtxt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfnamex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m N,L \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(x), \u001b[38;5;28mlen\u001b[39m(x[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      8\u001b[0m Show_data(x,L,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moriginal data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.9/site-packages/numpy/lib/npyio.py:1067\u001b[0m, in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, like)\u001b[0m\n\u001b[1;32m   1065\u001b[0m     fname \u001b[38;5;241m=\u001b[39m os_fspath(fname)\n\u001b[1;32m   1066\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_string_like(fname):\n\u001b[0;32m-> 1067\u001b[0m     fh \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_datasource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1068\u001b[0m     fencoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(fh, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1069\u001b[0m     fh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(fh)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.9/site-packages/numpy/lib/_datasource.py:193\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03mOpen `path` with `mode` and return the file object.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    189\u001b[0m \n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    192\u001b[0m ds \u001b[38;5;241m=\u001b[39m DataSource(destpath)\n\u001b[0;32m--> 193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnewline\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.9/site-packages/numpy/lib/_datasource.py:533\u001b[0m, in \u001b[0;36mDataSource.open\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _file_openers[ext](found, mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[1;32m    531\u001b[0m                               encoding\u001b[38;5;241m=\u001b[39mencoding, newline\u001b[38;5;241m=\u001b[39mnewline)\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 533\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m path)\n",
      "\u001b[0;31mOSError\u001b[0m: DATA/x_ts_L60_Z12_A500_DX50_bias5_N10000.dat not found."
     ]
    }
   ],
   "source": [
    "str0 = 'ts_L60_Z12_A500_DX50_bias5_N10000.dat'\n",
    "fnamex='DATA/x_'+str0\n",
    "fnamey='DATA/y_'+str0\n",
    "\n",
    "x = np.loadtxt(fnamex, delimiter=\" \",dtype=float)\n",
    "N,L = len(x), len(x[0])\n",
    "\n",
    "Show_data(x,L,\"original data\")\n",
    "\n",
    "# note: here it does not need to be converted to the 3-bit version, a label remains y[i]=0,1,2\n",
    "y = np.loadtxt(fnamey, dtype=int)\n",
    "n_class = 3    #  = len(np.unique(y))\n",
    "print('data: ',N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (do not) Rescale data\n",
    "We know that the average value of a sample is not relevant: let's see if XGBoost works if we do not remove such average and we do not standardize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESCALE=False\n",
    "if RESCALE:\n",
    "    #remove average value of each sample from its values\n",
    "    xm = x.mean(axis=1)\n",
    "    for i in range(N):\n",
    "        x[i] = x[i]-xm[i]\n",
    "\n",
    "    #rescale (crude version, variance should be used)\n",
    "    x = x/400\n",
    "\n",
    "    Show_data(x,L,\"rescaled data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSFRESH: extract features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input data format: DATAFRAME\n",
    "\n",
    "first column $\\to$ id of the sample \n",
    "\n",
    "second column $\\to$  id of the time step\n",
    "\n",
    "third column $\\to$ value of the feature of _id_-sample at _id_-step\n",
    "\n",
    "For more: https://tsfresh.readthedocs.io/en/latest/text/data_formats.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(x):\n",
    "    '''Build input dataframe for given data series\n",
    "    Input:\n",
    "    var = array of time series, (#samples,time,1)\n",
    "    Return:\n",
    "    df = dataframe ready for features extraction\n",
    "    '''\n",
    "    \n",
    "    #N = #samples, t = timesteps\n",
    "    N, t = x.shape[0], x.shape[1]\n",
    "    #build id columns\n",
    "    id_col = np.repeat(np.arange(N),t)\n",
    "    #build time columns\n",
    "    time_col = np.tile(np.arange(t),N)\n",
    "    #build var columns\n",
    "    x_col = x.flatten()\n",
    "      \n",
    "    #build dict for df\n",
    "    x_dict = {'id':id_col,'time':time_col,'value':x_col}\n",
    "        \n",
    "    #return dataframe\n",
    "    return pd.DataFrame(x_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get df\n",
    "df = get_df(x) \n",
    "\n",
    "#check that last columns, if reshaped is equal to x\n",
    "#df_to_array = df.values[:,-1].reshape(x.shape[0],x.shape[1])\n",
    "#sum of different values: should be 0\n",
    "#print('Differences:',np.sum(df_to_array != x))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract features\n",
    "x_features = extract_features(\n",
    "                            df, #our dataframe\n",
    "                            column_id='id', #sample id, from 0 to N\n",
    "                            column_sort='time', #timestep, from 0 to t\n",
    "                            column_kind=None, #we have only one feature\n",
    "                            column_value='value', #value of input \n",
    "                            n_jobs=4) #number of cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at x_features\n",
    "x_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove columns with NaN or inf\n",
    "x_features.replace([np.inf, -np.inf], np.nan)\n",
    "x_features = x_features.dropna(axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at clean x_features\n",
    "x_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into training and validation\n",
    "\n",
    "perc_train=0.8\n",
    "N_train = int(perc_train*N)\n",
    "x_train = x_features[:N_train]\n",
    "y_train = y[:N_train]\n",
    "x_val = x_features[N_train:]\n",
    "y_val = y[N_train:]\n",
    "N_val = len(x_val)\n",
    "print('N_train=',N_train,'  N_val=',N_val,'  n_class=',n_class)\n",
    "\n",
    "#rescale: in each feature, remove average and divide by std\n",
    "if True:\n",
    "    average = np.mean(x_train,axis=0)\n",
    "    x_train -= average\n",
    "    x_val -= average\n",
    "\n",
    "    std = np.std(x_train,axis=0)\n",
    "    x_train /= std\n",
    "    x_val /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at x_train\n",
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reproducibility\n",
    "np.random.seed(12345)\n",
    "\n",
    "#define parameters for xgboost\n",
    "params = {'max_depth':6,'min_child_weight':1,\\\n",
    "          'learning_rate':0.3,'use_label_encoder':False}\n",
    "\n",
    "#build model with given params\n",
    "model = XGBClassifier(**params)\n",
    "\n",
    "#fit\n",
    "model.fit(x_train.values,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot tree\n",
    "\n",
    "fig, AX = plt.subplots(3,1,figsize=(30, 10))\n",
    "for i in range(3):\n",
    "    ax=AX[i]\n",
    "    plot_tree(model, num_trees=i, ax=ax)\n",
    "    \n",
    "fig.savefig(\"DATA/trees-time-ser.png\", dpi=300, pad_inches=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#predict labels on training set\n",
    "y_pred_train = model.predict(x_train)\n",
    "#predict labels on validation set\n",
    "y_pred_val = model.predict(x_val)\n",
    "\n",
    "y_pred_val_soft = model.predict_proba(x_val)\n",
    "\n",
    "\n",
    "\n",
    "#compute accuracies\n",
    "acc_train = accuracy_score(y_train,y_pred_train) \n",
    "acc_val = accuracy_score(y_val,y_pred_val)\n",
    "\n",
    "#print accuracies\n",
    "print('Training accuracy:',acc_train)\n",
    "print('Validation accuracy:',acc_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "\n",
    "LABELS = [\"absent\",\"positive\",\"negative\"]\n",
    "cmap=\"GnBu\"\n",
    "\n",
    "def show_confusion_matrix(validations, predictions, label=\"Model\"):\n",
    "\n",
    "    matrix = metrics.confusion_matrix(validations, predictions)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(matrix,\n",
    "                xticklabels=LABELS,\n",
    "                yticklabels=LABELS,\n",
    "                annot=True,\n",
    "                fmt='d',\n",
    "                linecolor='white',\n",
    "                linewidths=1,\n",
    "                cmap=cmap)\n",
    "    plt.title(label+': Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "\n",
    "y_pred_val = model.predict(x_val)\n",
    "show_confusion_matrix(y_val, y_pred_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importances\n",
    "\n",
    "See an overview of extracted features:\n",
    "https://tsfresh.readthedocs.io/en/latest/text/list_of_features.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get feature names\n",
    "feature_names = x_features.columns.values\n",
    "\n",
    "#empty dict\n",
    "feat_imp = {}\n",
    "#get f importance from model\n",
    "for i,f in enumerate(feature_names):\n",
    "    feat_imp[f] = model.feature_importances_[i]\n",
    "#sort features depending on their importances\n",
    "feat_imp = dict(sorted(feat_imp.items(), reverse=True, key=lambda item: item[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "minval=0.005\n",
    "print('------------- Feature importance sum = '+str(np.sum(model.feature_importances_)))\n",
    "print('------------- Showing feature with importance > '+str(minval))\n",
    "for i,k in enumerate(feat_imp.keys()):\n",
    "    if feat_imp[k]>minval: print(i+1,k,feat_imp[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get feature names given importance order\n",
    "features = list(feat_imp.keys())\n",
    "\n",
    "#build dataframe for sns pairplot\n",
    "df = pd.DataFrame({'1':x_features[features[0]],\\\n",
    "                   '2':x_features[features[1]],\\\n",
    "                   '3':x_features[features[2]],\\\n",
    "                   '4':x_features[features[3]],\\\n",
    "                   '5':x_features[features[4]],\\\n",
    "                   'Class':y})\n",
    "#pairplot with seaborn\n",
    "pal = sns.blend_palette([\"blue\",\"red\",\"gold\"],n_class)\n",
    "sns.pairplot(df,hue='Class',plot_kws=dict(alpha=0.8),palette=pal);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
